{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain을 활용한 챗봇 구현\n",
    "\n",
    "### 1. Retrieval augmented generation\n",
    "\n",
    "- 문서를 바탕으로 질의 응답을 할 수 있는 봇을 만듭니다.\n",
    "\n",
    "### 2. 대화 히스토리를 고려한 RAG 챗봇\n",
    "\n",
    "- 단발성 질문이 아닌, 과거 질문 내역을 바탕으로 질문을 이어갈 수 있게끔 history를 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 기능을 가진 챗봇을 만들 예정입니다.\n",
    "\n",
    "1. 문서를 기반으로 관련성 있는 정보를 가져오는 봇\n",
    "2. 관련 정보를 바탕으로 사용자의 질문에 답변을 하는 봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Maximizing Muscle Hypertrophy.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PDF를 읽어 LangChain의 다른 컴포넌트에서 사용할 수 있는 Document의 형태로 변환합니다.\n",
    "- 읽는 파일이나 데이터의 종류에 따라 사용해야 하는 loader가 달라집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2019-12-06T03:19:50+01:00', 'moddate': '2019-12-06T03:19:50+01:00', 'source': 'Maximizing Muscle Hypertrophy.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='International  Journal  of \\nEnvironmental Research\\nand Public Health\\nReview\\nMaximizing Muscle Hypertrophy: A Systematic\\nReview of Advanced Resistance Training Techniques\\nand Methods\\nMichal Krzysztoﬁk *\\n , Michal Wilk\\n , Grzegorz Wojdała\\n and Artur Goła´ s\\nInstitute of Sport Sciences, Jerzy Kukuczka Academy of Physical Education in Katowice, ul. Mikolowska 72a,\\n40-065 Katowice, Poland; m.wilk@awf.katowice.pl (M.W.); wojdala.grzegorz@gmail.com (G.W.);\\na.golas@awf.katowice.pl (A.G.)\\n* Correspondence: m.krzysztoﬁk@awf.katowice.pl\\nReceived: 12 October 2019; Accepted: 3 December 2019; Published: 4 December 2019\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Background: Eﬀective hypertrophy-oriented resistance training (RT) should comprise a\\ncombination of mechanical tension and metabolic stress. Regarding training variables, the most\\neﬀective values are widely described in the literature. However, there is still a lack of consensus\\nregarding the e ﬃciency of advanced RT techniques and methods in comparison to traditional\\napproaches. Methods: MEDLINE and SPORTDiscus databases were searched from 1996 to September\\n2019 for all studies investigating the e ﬀects of advanced RT techniques and methods on muscle\\nhypertrophy and training variables. Thirty articles met the inclusion criteria and were consequently\\nincluded for the quality assessment and data extraction. Results: Concerning the time-e ﬃciency of\\ntraining, the use of agonist–antagonist, upper–lower body supersets, drop and cluster sets, sarcoplasma\\nstimulating training, employment of fast, but controlled duration of eccentric contractions (~2s),\\nand high-load RT supplemented with low-load RT under blood ﬂow restriction may provide an\\nadditional stimulus and an advantage to traditional training protocols. With regard to the higher\\ndegree of mechanical tension, the use of accentuated eccentric loading in RT should be considered.\\nImplementation of drop sets, sarcoplasma stimulating training, low-load RT in conjunction with\\nlow-load RT under blood ﬂow restriction could provide time-eﬃcient solutions to increased metabolic\\nstress. Conclusions: Due to insu ﬃcient evidence, it is di ﬃcult to provide speciﬁc guidelines for\\nvolume, intensity of e ﬀort, and frequency of previously mentioned RT techniques and methods.\\nHowever, well-trained athletes may integrate advanced RT techniques and methods into their routines\\nas an additional stimulus to break through plateaus and to prevent training monotony.\\nKeywords: muscle growth; drop sets; supersets; accentuated eccentric work; blood ﬂow restriction;\\npre-exhaustion; sarcoplasma stimulating training; movement tempo\\n1. Introduction\\nResistance training (RT) is a primary exercise intervention used to develop strength and stimulate\\nmuscle hypertrophy. Increases in muscle mass constitute key components of conditioning in\\nvarious sports due to the correlation between muscle cross-sectional area and muscle strength [1,2].\\nAdditionally, an increase in muscle mass is one of the goals of bodybuilding [3], and many recreationally\\nstrength-trained individuals. Furthermore, adequate levels of muscle mass are an important issue from\\na health standpoint because its low levels are associated with increased risks of several diseases such\\nas cardiovascular disease [4] and cardio-metabolic risk in adolescents [5] as well as type II diabetes in\\nmiddle aged and older adults [6].\\nMuscle hypertrophy occurs when muscle protein synthesis exceeds muscle protein breakdown\\nand results in positive net protein balance in cumulative periods [ 7]. This could be achieved with\\nInt. J. Environ. Res. Public Health 2019, 16, 4897; doi:10.3390/ijerph16244897 www.mdpi.com /journal/ijerph')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텍스트를 LLM에 활용하기 위해서는 사용자의 '질문'과 연관된 정보를 외부에서 제공해줄 수 있어야 합니다.\n",
    "- '질문'과의 연관성을 측정하기 위한 방법이 embedding 유사도 측정입니다.\n",
    "- 텍스트를 벡터의 형태로 변환하고, 벡터간의 similarity를 측정함으로써 두 텍스트의 '연관성'을 숫자로 표현할 수 있습니다.\n",
    "- 따라서 활용하고자 하는 파일에 있는 텍스트를 벡터로 변환하고 저장해야 활용할 수 있습니다.\n",
    "    - 가장 첫 번째 단계는 텍스트를 split하여 저장하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #A5B68D; border-radius: 5px; padding: 2px 6px; border: 1px solid #ccc; font-family: sans-serif;\">\n",
    "    retriever</span>에는 아주 많은 기능이 내포되어 있습니다.\n",
    "코드를 실행함으로서 다음 스텝들이 내부에서 실행됩니다.\n",
    "\n",
    "1. Document 내에 있는 text를 추출\n",
    "2. 추가할 meta data가 있다면 추가\n",
    "3. Text를 embedding vector로 변환 (이때 embedding model 활용)\n",
    "4. Embedding vector를 vectorDB에 적재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심화된 내용을 공부하고 싶으시면 : Retrieval augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_chroma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_chroma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_documents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_chroma'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# -- 여러 문서 정보를 input으로 받아서 이를 연결하는 작업을 수행\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain \n",
    "# -- vector DB 에서 데이터 검색 및 llm통해 답변 생성까지 할 수 있도록 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 00 청크로 쪼갠 문서 정보 -> vector 로 변환해서 저장\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "  ## from_documents : txt > emb vector\n",
    "  ## documents : 입력하고자 하는 문서 정보 (청크 단위로 쪼개진 문자열 리스트)\n",
    "  ## embedding: embedding 모델의 정의\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "  ## 크로마 벡터 디비에 저장된 문서 벡터 정보를 가지고 유사한 문서를 검색하는 객체 (검색기) 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain`는 이전에 텍스트에서 변환된 document 객체를 chain에 연결하기 위한 wrapper 입니다.\n",
    "\n",
    "따라서 llm, prompt와 함께 retriever도 chain에 연결하여 실행 할 수 있도록 합니다.\n",
    "\n",
    "`create_retrieval_chain`는 이렇게 준비된 chain들을 모두 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"\"\"당신은 질문-답변을 담당하는 전문가 입니다. 다음 정보를 활용하여 질문에 답을 하시오. \n",
    "    모르면 모른다고 답하고, 답변은 간결하게 하시오.\n",
    "    {context}\"\"\"\n",
    ")\n",
    "\n",
    "# 템플릿 객체 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## retriever 의 결과 (가장 유사도 높은 정보들) 를 바탕으로 프롬프트를 완성시키고 llm 에 전달함. \n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"현재 논문의 주제가 뭐야?\"})\n",
    "response[\"answer\"]\n",
    "\n",
    "# retriever | prompt | llm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재는 `retriever` -> `prompt` -> `llm` 순서대로 정보가 흐릅니다.\n",
    "\n",
    "retriever를 통해 정보가 prompt에 전달이 되고, 완성된 prompt가 LLM에게 전달이 되어 답변이 생성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 대화 히스토리를 고려한 RAG 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"논문 리뷰 전문가 입니다. 사용자의 질문에 답하세요. {context}\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "# session_id를 key로 삼아 dictionary에 저장\n",
    "# value 값에는 chat history를 저장\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"논문의 주제가 뭐야?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"paperbot\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"논문에서 이야기 하는 근육을 키우는 가장 좋은 방법은 뭐야?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"paperbot\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
